{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, ParameterGrid\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>plant-stand</th>\n",
       "      <th>precip</th>\n",
       "      <th>temp</th>\n",
       "      <th>hail</th>\n",
       "      <th>crop-hist</th>\n",
       "      <th>area-damaged</th>\n",
       "      <th>severity</th>\n",
       "      <th>seed-tmt</th>\n",
       "      <th>germination</th>\n",
       "      <th>...</th>\n",
       "      <th>sclerotia</th>\n",
       "      <th>fruit-pods</th>\n",
       "      <th>fruit-spots</th>\n",
       "      <th>seed</th>\n",
       "      <th>mold-growth</th>\n",
       "      <th>seed-discolor</th>\n",
       "      <th>seed-size</th>\n",
       "      <th>shriveling</th>\n",
       "      <th>roots</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>april</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>upper-areas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2-4-d-injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>april</td>\n",
       "      <td>lt-normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lt-norm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>diff-lst-year</td>\n",
       "      <td>scattered</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rotted</td>\n",
       "      <td>herbicide-injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>june</td>\n",
       "      <td>lt-normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lt-norm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>diff-lst-year</td>\n",
       "      <td>scattered</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rotted</td>\n",
       "      <td>herbicide-injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>april</td>\n",
       "      <td>lt-normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lt-norm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>same-lst-yr</td>\n",
       "      <td>whole-field</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rotted</td>\n",
       "      <td>herbicide-injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>june</td>\n",
       "      <td>lt-normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lt-norm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>same-lst-yr</td>\n",
       "      <td>whole-field</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rotted</td>\n",
       "      <td>herbicide-injury</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date plant-stand precip     temp hail      crop-hist area-damaged  \\\n",
       "678  april         NaN    NaN      NaN  NaN            NaN  upper-areas   \n",
       "679  april   lt-normal    NaN  lt-norm  NaN  diff-lst-year    scattered   \n",
       "680   june   lt-normal    NaN  lt-norm  NaN  diff-lst-year    scattered   \n",
       "681  april   lt-normal    NaN  lt-norm  NaN    same-lst-yr  whole-field   \n",
       "682   june   lt-normal    NaN  lt-norm  NaN    same-lst-yr  whole-field   \n",
       "\n",
       "    severity seed-tmt germination  ... sclerotia fruit-pods fruit-spots seed  \\\n",
       "678      NaN      NaN         NaN  ...       NaN        NaN         NaN  NaN   \n",
       "679      NaN      NaN         NaN  ...       NaN        dna         NaN  NaN   \n",
       "680      NaN      NaN         NaN  ...       NaN        dna         NaN  NaN   \n",
       "681      NaN      NaN         NaN  ...       NaN        dna         NaN  NaN   \n",
       "682      NaN      NaN         NaN  ...       NaN        dna         NaN  NaN   \n",
       "\n",
       "    mold-growth seed-discolor seed-size shriveling   roots             class  \n",
       "678         NaN           NaN       NaN        NaN     NaN      2-4-d-injury  \n",
       "679         NaN           NaN       NaN        NaN  rotted  herbicide-injury  \n",
       "680         NaN           NaN       NaN        NaN  rotted  herbicide-injury  \n",
       "681         NaN           NaN       NaN        NaN  rotted  herbicide-injury  \n",
       "682         NaN           NaN       NaN        NaN  rotted  herbicide-injury  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:/FDEC/soybean.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2337"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 36)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = df[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.isna().any()\n",
    "#no missing values in the target so no need to impute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='class', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to handle NaN for categorical variables, we'll use the most frequent value in each variable\n",
    "categ_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data= categ_pipeline.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\33752\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#we will encode the label but no imputing since it doesn't contain any missing values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9562043795620438\n",
      "0.9547487792013339\n"
     ]
    }
   ],
   "source": [
    "#let's use the randomforest and calculate the accuracy using the train/test split\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_score = rf.predict(X_test)\n",
    "accuracy = rf.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "print(f1_score(y_test, y_score, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is high about 97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9283490768570202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\33752\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9399403239556692\n"
     ]
    }
   ],
   "source": [
    "#let's use the cross validation for the randomforest\n",
    "score_5 = cross_val_score(rf, data, y, cv=5)\n",
    "print(score_5.mean())\n",
    "score_10 = cross_val_score(rf, data, y, cv=10)\n",
    "print(score_10.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracy is high about 97% and the score using 10 folds is better than using 5 folds not the same results as we got using weka\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's tune the hyperparameters to get better performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [i for i in range(10, 100, 10)],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best estimator here using 5 folds is the RandomForest with entropy and max features as sqrt and n_estimators 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\33752\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_features': 'auto', 'n_estimators': 50}\n",
      "0.9303367003367005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=10)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best estimator for using 10 folds is: RandomForestClassifier(criterion='entropy', n_estimators=50)\n"
     ]
    }
   ],
   "source": [
    "print('the best estimator for using 10 folds is:', grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's use the bagging using decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9635036496350365\n",
      "0.9645823195458232\n"
     ]
    }
   ],
   "source": [
    "bc = BaggingClassifier(tree.DecisionTreeClassifier(), max_samples=0.5, max_features=0.5, n_estimators=200)\n",
    "bc.fit(X_train, y_train)\n",
    "y_score = bc.predict(X_test).copy()\n",
    "accuracy = bc.score(X_test, y_test)\n",
    "\n",
    "print(accuracy)\n",
    "print(f1_score(y_test, y_score, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 96% and the f1_score is 96% so the model performs well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9224774581365391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\33752\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9282608695652174\n"
     ]
    }
   ],
   "source": [
    "#let's use the cross validation and see the scores\n",
    "score_5 = cross_val_score(bc, data, y, cv=5)\n",
    "print(score_5.mean())\n",
    "score_10 = cross_val_score(bc, data, y, cv=10)\n",
    "print(score_10.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THe model performs good but not better than the split train/test because the accuracy is lower also for the f1_score but the model is not generelized since using train/test split it overfits than using cross validation so it could not perform better on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's us the adaaboost with the decision tree as base classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9635036496350365\n",
      "0.9641899057957452\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(tree.DecisionTreeClassifier(), n_estimators=500)\n",
    "abc.fit(X_train, y_train)\n",
    "y_score = abc.predict(X_test).copy()\n",
    "accuracy = abc.score(X_test, y_test)\n",
    "\n",
    "print(accuracy)\n",
    "print(f1_score(y_test, y_score, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the accuracy and f_score are the same as using the bagging on train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9224667239158437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\33752\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9310954816709293\n"
     ]
    }
   ],
   "source": [
    "score_5 = cross_val_score(abc, data, y, cv=5)\n",
    "print(score_5.mean())\n",
    "score_10 = cross_val_score(abc, data, y, cv=10)\n",
    "print(score_10.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score here is higher than using the bagging but for using the train/test split it is lower but more generelizing as model it can perform better on unseen data than using the train/test split that use all its data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9124087591240876\n",
      "0.9082923633840493\n"
     ]
    }
   ],
   "source": [
    "#let's use the gradientboost on the decisiontree classifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=200)\n",
    "gbc.fit(X_train, y_train)\n",
    "y_score = gbc.predict(X_test).copy()\n",
    "accuracy = gbc.score(X_test, y_test)\n",
    "\n",
    "print(accuracy)\n",
    "print(f1_score(y_test, y_score, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy and f-score here are lower than the other classifiers since we used lower number for estimator but it stays a good model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298089308716186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\33752\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9223785166240409\n"
     ]
    }
   ],
   "source": [
    "score_5 = cross_val_score(gbc, data, y, cv=5)\n",
    "print(score_5.mean())\n",
    "score_10 = cross_val_score(gbc, data, y, cv=10)\n",
    "print(score_10.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score using the 5 folds is better than 10 folds is the same results we got using weka and it is better than using train/test split since it is more generelizing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's use the votingclassifier to ensemble all the models we use\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "bag = BaggingClassifier()\n",
    "bag.fit(X_train, y_train)\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, y_train)\n",
    "grad = GradientBoostingClassifier()\n",
    "grad.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf1 = VotingClassifier(estimators=[('rf', rf), ('bc', bag), ('abc', ada), ('gbc', grad)])\n",
    "eclf1.fit(X_train, y_train)\n",
    "y_pred = eclf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948905109489051\n",
      "0.9479412315178738\n",
      "0.9356590811507084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\33752\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9370417732310315\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(cross_val_score(rf, data, y, cv=5).mean())\n",
    "print(cross_val_score(rf, data, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracy of the ensembling method using the voting with all classifiers is overall better than each model appart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
